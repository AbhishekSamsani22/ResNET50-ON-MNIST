# -*- coding: utf-8 -*-
"""ResNet_MNIST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JOTUlzpnb8Tcx677DyQ4bOIX5xIST_HT
"""

#importing tensorflow
import tensorflow as tf
import numpy as np
#loading mnist dataset
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

#importing matplotlib library for plotting
import matplotlib.pyplot as plt
image_index = 255 # You may select anything up to 60,000
print(y_train[image_index]) # The label is 8
plt.imshow(x_train[image_index], cmap='Greys') #printing the image

#checking the shape of the data
x_train.shape

# Reshaping the array to 4-dims so that it can work with the Keras API
x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)
x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)
input_shape = (28, 28, 1)
# Making sure that the values are float so that we can get decimal points after division
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
# Normalizing the RGB codes by dividing it to the max RGB value.
x_train /= 255
x_test /= 255
print('x_train shape:', x_train.shape)
print('Number of images in x_train', x_train.shape[0])
print('Number of images in x_test', x_test.shape[0])

#  Create base model of ResNet50
from keras.applications.resnet50 import ResNet50
from keras.preprocessing import image
from keras.applications.resnet50 import preprocess_input

IMG_HEIGHT = 32
IMG_WIDTH = 32
DEPTH = 3
#loading ResNet weights from directory
model = ResNet50(weights='/content/drive/My Drive/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',
                  include_top=False, 
                  input_shape=(IMG_HEIGHT, IMG_WIDTH, DEPTH)
                 )
model.summary()
#Drive Link For Downloading the model: https://drive.google.com/open?id=1iwzypt3s7PEwwDTMvINUbimX55PqccIS

from google.colab import drive
drive.mount('/content/drive')

# Importing the required Keras modules containing model and layers
from keras.models import Sequential
from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D
# adding our output model
model = Sequential() 
#Adding convolution layer
model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))
# Adding maxpooling layer
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Flatten()) # Flattening the 2D arrays for fully connected layers
model.add(Dense(128, activation=tf.nn.relu))
#Adding dropout to avoid overfitting
model.add(Dropout(0.5))
model.add(Dense(10,activation=tf.nn.softmax))

model.compile(optimizer='sgd',
              loss='sparse_categorical_crossentropy', 
              metrics=['accuracy'])
history = model.fit(x=x_train,y=y_train, validation_data=(x_test, y_test), epochs=100,validation_split=0.2,batch_size=500)

# plot the loss and accuracy

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(acc) + 1)

plt.title('Training and validation accuracy')
plt.plot(epochs, acc, 'red', label='Training accuracy')
plt.plot(epochs, val_acc, 'blue', label='Validation accuracy')
plt.legend()

plt.figure()
plt.title('Training and validation loss')
plt.plot(epochs, loss, 'red', label='Training loss')
plt.plot(epochs, val_loss, 'blue', label='Validation loss')

plt.legend()

plt.show()

#Evaluating our model performance

model.evaluate(x_test, y_test)

# Testing our model on an image

image_index = 622
plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')
pred = model.predict(x_test[image_index].reshape(1, 28, 28, 1))
print(pred.argmax())



# You would see image and also the number above that image

